{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modified_WPM_10_26.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8-YzhzdtP-7"
      },
      "source": [
        "# Primary objectives:\n",
        "-1. Run current model with 100% of the data.  The model is a proof on concept and intended to be tested on data it was trained on, but with noise inserted into the model.  See objectives below. \n",
        "\n",
        "2.1. Create a function to convert the model output to the exact format as the \"words\" matrix below. name the function to convert the data **out_to_arp** \n",
        "\n",
        "2.2. Convert the output of the ANN to create a matrix in the **exact format** as the \"words\" matrix below.\n",
        "\n",
        "3.1 Save the current ANN model as \"WordProd\" so that it can be tested on a subsets of the data it was trained on.  **I recogonize this is not typical for ANN models, but it is 100% necessary for this project**\n",
        "\n",
        "3.2. Test the WordProd model on the following data from the \"test\" command below. Plot test accuracy and loss as in the original model, because the original model was trained on this, the model should have accuracy near ceiling.\n",
        "\n",
        "4.  Convert the output of  \"WordProd\" to create a matrix in the **exact format** as the \"words\" matrix below using the previously created \n",
        "**out_to_arp** function. Name this m atrix, PNT_output.\n",
        "\n",
        "5. Create a unique function to add noise to each hidden layer. If possible, gaussian noise. \n",
        "\n",
        "6. Create example of how to test accuracy of the WordProd model on the \"test\" data after inserting noise.  Plot test accuracy and loss as in the original model, accuracy is now expected to perform NOT at ceiling. Make sure to test on the \"test\" words only.\n",
        "\n",
        "7. Convert the output of the \"WordProd\" with added noise to  a matrix in the **exact format** as the \"words\" matrix below using the previously created **out_to_arp** function. Name the output, Noisy_output \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVefn7NvxOyl"
      },
      "source": [
        "test = 'https://raw.githubusercontent.com/AlexSwiderski/SwiderskiLakhani/main/PNT_TEST.csv'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZoh3zLKEZ1o"
      },
      "source": [
        "The purpose of this notebook is to create a deep learning model that predicts sound/letter sequences from 300 dimensional word embeddings extracted from GLOVE. The current architecture includes 2 bidirectional recurrent layers and a fully connected hidden layer.\n",
        "\n",
        "Originally, I planned for the output layer to be similar to the following image:\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "In this matrix, each number corresponds to a letter and each word is represented by a series of numbers in each row vector. However, it occurred to me that using a crossentropy loss function would be better for this multi-label classification problem.  Therefore, I now must transform the row vectors into one-hot-encoded vectors and this is where I need help.\n",
        "\n",
        "I will outline questions throughout the code below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hc-oc_FGPR8"
      },
      "source": [
        "### Load required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-3O1SPxYXEt",
        "outputId": "353ed6b5-9f37-47cb-e223-24d463a6f0b3"
      },
      "source": [
        "!pip install torchtext==0.4.0 --quiet\n",
        "!pip install unidecode --quiet\n",
        "!pip install d2l --quiet\n",
        "!pip install nltk --quiet\n",
        "\n",
        "# Imports\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import gensim\n",
        "from gensim.matutils import corpus2csc\n",
        "from gensim.corpora import Dictionary\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import tqdm\n",
        "#import pdb\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import HTML\n",
        "from torchvision import transforms\n",
        "%unload_ext google.colab.data_table\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 53 kB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.3 MB/s \n",
            "\u001b[?25hThe google.colab.data_table extension is not loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOh0XtZYBHS2"
      },
      "source": [
        "# Imports\n",
        "import math\n",
        "import time\n",
        "import nltk\n",
        "import random\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torchtext import data, datasets\n",
        "\n",
        "from d2l import torch as d2l"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XilooY8YH2GZ"
      },
      "source": [
        "## Below I create an integer representation of each sound included in the 'words' matrix.  I originally planned to model the output for the DNN with these representations. However, to utilize cross entropy loss with a multi-label classification problem this seems to be causing problems. \n",
        "\n",
        "### **This code should not be included in the output layer of the ANN,** but I would like to keep it in the notebook for now as reference for later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YZF64_ddwQK"
      },
      "source": [
        "#original plan, unclear if this is the right way to go.\n",
        "replace_phons = {'':0,\n",
        "'AA' :1,\n",
        "\n",
        "'AE' :2,\n",
        "\n",
        "'AH' :3,\n",
        "\n",
        "'AO' :4,\n",
        "\n",
        "'AW' :5,\n",
        "\n",
        "'AY' :6,\n",
        "\n",
        "'B' :7,\n",
        "\n",
        "'CH' :8,\n",
        "\n",
        "'D' :9,\n",
        "\n",
        "'DH' :10,\n",
        "\n",
        "'EH' :11,\n",
        "\n",
        "'ER' :12,\n",
        "\n",
        "'EY' :13,\n",
        "\n",
        "'F' :14,\n",
        "\n",
        "'G' :15,\n",
        "\n",
        "'HH' :16,\n",
        "\n",
        "'IH' :17,\n",
        "\n",
        "'IY' :18,\n",
        "\n",
        "'JH' :19,\n",
        "\n",
        "'K' :20,\n",
        "\n",
        "'L' :21,\n",
        "\n",
        "'M' :22,\n",
        "\n",
        "'N' :23,\n",
        "\n",
        "'NG' :24,\n",
        "\n",
        "'OW' :25,\n",
        "\n",
        "'OY' :26,\n",
        "\n",
        "'P' :27,\n",
        "\n",
        "'R' :28,\n",
        "\n",
        "'S' :29,\n",
        "\n",
        "'SH' :30,\n",
        "\n",
        "'T' :31,\n",
        "\n",
        "'TH' :32,\n",
        "\n",
        "'UH' :33,\n",
        "\n",
        "'UW' :34,\n",
        "\n",
        "'V' :35,\n",
        "\n",
        "'W' :36,\n",
        "\n",
        "'Y' :37,\n",
        "\n",
        "'Z' :38,\n",
        "\n",
        "'ZH' :39}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9s0gmHyGbOP"
      },
      "source": [
        "## Load data, format colums etc.\n",
        "### Columns 1:11 will be the output layer of the ANN and it will need to be transformed to one-hot-encoded vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "GWCQU1OeYZcS",
        "outputId": "7aa9a705-f1f7-4daf-bcd1-3336d4a749aa"
      },
      "source": [
        "#ChNGED TO MATCH NEW INPUT WORDS\n",
        "#url = 'https://raw.githubusercontent.com/AlexSwiderski/SwiderskiLakhani/main/Just_Item_Names.csv'\n",
        "url = 'https://raw.githubusercontent.com/AlexSwiderski/SwiderskiLakhani/main/UpdatedWordList.csv'\n",
        "words = pd.read_csv(url)\n",
        "words.fillna('', inplace = True)\n",
        "words.columns = ['Word', '1', '2', '3', '4', '5', '6','7', '8', '9', '10', '11']\n",
        "\n",
        "#drop last empty row in words\n",
        "# Drop last 3 rows of dataframe\n",
        "N = 1\n",
        "words.drop(index=words.index[-N], \n",
        "        axis=0, \n",
        "        inplace=True)\n",
        "\n",
        "words"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bear</td>\n",
              "      <td>B</td>\n",
              "      <td>EH</td>\n",
              "      <td>R</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>beaver</td>\n",
              "      <td>B</td>\n",
              "      <td>IY</td>\n",
              "      <td>V</td>\n",
              "      <td>ER</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bee</td>\n",
              "      <td>B</td>\n",
              "      <td>IY</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bird</td>\n",
              "      <td>B</td>\n",
              "      <td>ER</td>\n",
              "      <td>D</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bug</td>\n",
              "      <td>B</td>\n",
              "      <td>AH</td>\n",
              "      <td>G</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>map</td>\n",
              "      <td>M</td>\n",
              "      <td>AE</td>\n",
              "      <td>P</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>flower</td>\n",
              "      <td>F</td>\n",
              "      <td>L</td>\n",
              "      <td>AW</td>\n",
              "      <td>ER</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1351</th>\n",
              "      <td>mountain</td>\n",
              "      <td>M</td>\n",
              "      <td>AW</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>AH</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1352</th>\n",
              "      <td>tree</td>\n",
              "      <td>T</td>\n",
              "      <td>R</td>\n",
              "      <td>IY</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1353</th>\n",
              "      <td>volcano</td>\n",
              "      <td>V</td>\n",
              "      <td>AA</td>\n",
              "      <td>L</td>\n",
              "      <td>K</td>\n",
              "      <td>EY</td>\n",
              "      <td>N</td>\n",
              "      <td>OW</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1354 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word  1   2   3   4   5  6   7 8  9  10 11\n",
              "0         bear  B  EH   R                           \n",
              "1       beaver  B  IY   V  ER                       \n",
              "2          bee  B  IY                               \n",
              "3         bird  B  ER   D                           \n",
              "4          bug  B  AH   G                           \n",
              "...        ... ..  ..  ..  ..  .. ..  .. .. .. .. ..\n",
              "1349       map  M  AE   P                           \n",
              "1350    flower  F   L  AW  ER                       \n",
              "1351  mountain  M  AW   N   T  AH  N                \n",
              "1352      tree  T   R  IY                           \n",
              "1353   volcano  V  AA   L   K  EY  N  OW            \n",
              "\n",
              "[1354 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFCd0EjrGhvC"
      },
      "source": [
        "## Load the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9jUNeSnvyiku",
        "outputId": "99f57da0-f2ad-42ae-f257-560ad4b09493"
      },
      "source": [
        "#ChNGED TO MATCH NEW INPUT WORDS\n",
        "#url = 'https://raw.githubusercontent.com/AlexSwiderski/SwiderskiLakhani/main/Just_Item_Names.csv'\n",
        "url = test\n",
        "words_test = pd.read_csv(url , header=None)\n",
        "words_test.fillna('', inplace = True)\n",
        "\n",
        "words_test"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anchor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>baby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>whistle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>wig</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>window</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>zebra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>zipper</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0\n",
              "0    ambulance\n",
              "1       anchor\n",
              "2        apple\n",
              "3         baby\n",
              "4         ball\n",
              "..         ...\n",
              "170    whistle\n",
              "171        wig\n",
              "172     window\n",
              "173      zebra\n",
              "174     zipper\n",
              "\n",
              "[175 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90SOLNnkt-uO"
      },
      "source": [
        "## get the target from the dataset which need to measure the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ-cotB4t93n"
      },
      "source": [
        "test_set = []\n",
        "for idx , row in enumerate(words_test.iterrows() ):\n",
        "  i_word = row[1][0]\n",
        "  #get index corresponds to the initial dataset\n",
        "  word_idx = np.nonzero( np.array( words.Word==i_word , dtype=np.int64) )\n",
        "  if( len(word_idx[0]) !=0 ):\n",
        "    index = word_idx[0][0]\n",
        "    row_in_dataset = words.iloc[ index ]\n",
        "    test_set.append( row_in_dataset)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFqhIOVMwYgC"
      },
      "source": [
        "test_words = pd.DataFrame( test_set )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1dcFL-6Gmkg"
      },
      "source": [
        "## Below is a clear representation of what the output data looks like. Note that the first column 'word' will not be included in the output layer.  However, the letter sequences representing each word can be clearly seen.\n",
        "### Again, columns 1:11 will be the output layer, but need to first be transformed to one hot encoded vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EOsGq4rpysCf",
        "outputId": "2b77b4a9-bf86-465e-d497-4f1f2148bbf5"
      },
      "source": [
        "words"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bear</td>\n",
              "      <td>B</td>\n",
              "      <td>EH</td>\n",
              "      <td>R</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>beaver</td>\n",
              "      <td>B</td>\n",
              "      <td>IY</td>\n",
              "      <td>V</td>\n",
              "      <td>ER</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bee</td>\n",
              "      <td>B</td>\n",
              "      <td>IY</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bird</td>\n",
              "      <td>B</td>\n",
              "      <td>ER</td>\n",
              "      <td>D</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bug</td>\n",
              "      <td>B</td>\n",
              "      <td>AH</td>\n",
              "      <td>G</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>map</td>\n",
              "      <td>M</td>\n",
              "      <td>AE</td>\n",
              "      <td>P</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>flower</td>\n",
              "      <td>F</td>\n",
              "      <td>L</td>\n",
              "      <td>AW</td>\n",
              "      <td>ER</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1351</th>\n",
              "      <td>mountain</td>\n",
              "      <td>M</td>\n",
              "      <td>AW</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>AH</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1352</th>\n",
              "      <td>tree</td>\n",
              "      <td>T</td>\n",
              "      <td>R</td>\n",
              "      <td>IY</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1353</th>\n",
              "      <td>volcano</td>\n",
              "      <td>V</td>\n",
              "      <td>AA</td>\n",
              "      <td>L</td>\n",
              "      <td>K</td>\n",
              "      <td>EY</td>\n",
              "      <td>N</td>\n",
              "      <td>OW</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1354 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word  1   2   3   4   5  6   7 8  9  10 11\n",
              "0         bear  B  EH   R                           \n",
              "1       beaver  B  IY   V  ER                       \n",
              "2          bee  B  IY                               \n",
              "3         bird  B  ER   D                           \n",
              "4          bug  B  AH   G                           \n",
              "...        ... ..  ..  ..  ..  .. ..  .. .. .. .. ..\n",
              "1349       map  M  AE   P                           \n",
              "1350    flower  F   L  AW  ER                       \n",
              "1351  mountain  M  AW   N   T  AH  N                \n",
              "1352      tree  T   R  IY                           \n",
              "1353   volcano  V  AA   L   K  EY  N  OW            \n",
              "\n",
              "[1354 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkjn75-UHdnt"
      },
      "source": [
        "## Next we load the glove-wiki-gigaworld data set that includes the 300d embeddings.  This takes about 5 min. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G54mD1oQZf0Y"
      },
      "source": [
        "#Method 1: Get word embeddings for all available words from Wikigigaworld.\n",
        "import gensim.downloader as api\n",
        "# Download dataset\n",
        "glove_model300 = api.load('glove-wiki-gigaword-300')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyvxPGLwHoPF"
      },
      "source": [
        "## Here I create a matrix X2 that includes the 300d word embeddings for each item."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAHXFEqUaxGa"
      },
      "source": [
        "#word_array = np.empty((0, 300))\n",
        "\n",
        "def data_preprocessing( input_dataframe ):\n",
        "\n",
        "  X = input_dataframe['Word'].copy()\n",
        "\n",
        "  X2 , raw_word = [] , []\n",
        "  yfound = []\n",
        "  for idx, row in enumerate(X):\n",
        "      try:\n",
        "          word_array = np.empty((0, 300))\n",
        "          result = glove_model300.word_vec(row)\n",
        "          word_array = np.append(word_array, [result], axis = 0)\n",
        "          X[idx] = result\n",
        "          X2.append(result)\n",
        "          raw_word.append( row )\n",
        "\n",
        "      except:\n",
        "          #X[idx] = 'None'\n",
        "          pass\n",
        "\n",
        "  \"\"\" \n",
        "  y is intended to become the outcome for the DNN\n",
        "  \"\"\"\n",
        "  #sorted_data\n",
        "  input_dataframe.columns = ['Word', '1', '2', '3', '4', '5', '6','7', '8', '9', '10', '11']\n",
        "  #phon = phon.iloc[:-1 , :]\n",
        "  y = input_dataframe\n",
        "  y = y.drop('Word', axis = 1)\n",
        "  for col in y.columns: \n",
        "    # apply the replace_phons dictionary on y each column except word & fill nan values with 0's\n",
        "    y[col] = y[col].map(replace_phons).fillna(0)\n",
        "  \n",
        "\n",
        "  return np.array(raw_word) , np.array(X2) , y.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teauDbp-yXSv"
      },
      "source": [
        "## Preprocesses the train dataset before feed into the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuMf1dWtyW7g"
      },
      "source": [
        "raw_words , X_in , y_in = data_preprocessing( words ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_eHgegDf65c"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# convert the indexed numpy array into torch tensor with int64 dtype\n",
        "y_tensor = torch.tensor( y_in , dtype=torch.int64 )\n",
        "# troech tensor one hot encoding\n",
        "y_one_hot_encoding = F.one_hot(y_tensor, num_classes=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmJyxTvr0xiR"
      },
      "source": [
        "# convert the X_in , y into torch tenors\n",
        "X_in = torch.from_numpy(X_in)\n",
        "y = y_one_hot_encoding\n",
        "raw_words = np.array( raw_words )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fg3DCqBDJXs"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)\n",
        "\n",
        "  # @title Set device (GPU or CPU). Execute `set_device()`\n",
        "# especially if torch modules used.\n",
        "\n",
        "# inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9jsb8OsJgOM"
      },
      "source": [
        "## Set seed and device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leztDGfwDODR",
        "outputId": "d0530d77-e2cc-4d5a-b4ba-afb2b8228429"
      },
      "source": [
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n",
            "WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -> `Change runtime type.`  select `GPU` \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lRLjT1GJi4w"
      },
      "source": [
        "## Create custom data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfcv2l71EX01"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, raw_word , dat, labels):\n",
        "        self.labels = labels\n",
        "        self.dat = dat\n",
        "        self.raw_word = raw_word\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        dat = self.dat[idx]\n",
        "        i_word = self.raw_word[idx]\n",
        "\n",
        "        sample = { \"Sample_word\":i_word , \"Sample\": dat, \"Class\": label}\n",
        "        return sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN8l8ZR7Jyk7"
      },
      "source": [
        "## Defiing parameters for the RNN and creating the train and validation set.  I know that the train/test are the same right now.  That is fine and I will play with that later. As long as they both run, that will be sufficient. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAz9fODk4Xfk",
        "outputId": "95bdb00b-e4ce-436e-c31e-a235ba60a28b"
      },
      "source": [
        "# Splitting dataset\n",
        "# Uncler what the batch size should be\n",
        "batch_size = 11\n",
        "# get the indices for the index for the dataset\n",
        "index_set = np.arange( len(y) )\n",
        "# shuffle the indices\n",
        "random.shuffle( index_set )\n",
        "# define train , val split as 0.8 train , 0.2 valid\n",
        "train_val_split = 1.0\n",
        "train_limit = int( train_val_split * len(y)  )\n",
        "# extract train and validation indices\n",
        "train_index , val_index = index_set , index_set\n",
        "\n",
        "# define train and validation datasets \n",
        "x_train , y_train = X_in[ train_index ] , y[ train_index ]\n",
        "x_valid , y_valid = X_in[ val_index ]   , y[ val_index ]\n",
        "raw_words_train , raw_words_valid = raw_words[ train_index ] , raw_words[ val_index ]\n",
        "\n",
        "# define data loaders for each train and test \n",
        "train_dset = CustomDataset( raw_words_train , x_train , y_train )  # create data set\n",
        "train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True) #load data with batch size\n",
        "valid_dset = CustomDataset( raw_words_valid ,  x_valid , y_valid )\n",
        "valid_loader = DataLoader(valid_dset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa3a8cd21d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSFXoFYBt454"
      },
      "source": [
        "# Imports\n",
        "import math\n",
        "import time\n",
        "import nltk\n",
        "import random\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torchtext import data, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from d2l import torch as d2l"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPomwdTwIBj5"
      },
      "source": [
        "class VanillaRNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(VanillaRNN, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.bidirectional = True\n",
        "        self.decoder_length = 11\n",
        "        self.input_size = input_size\n",
        "\n",
        "        #Defining the layers\n",
        "        # input encoder model --> which used to map the input size to match with hidden_dim\n",
        "        self.encoder_input = nn.Linear( self.input_size , hidden_dim )\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN( hidden_dim , hidden_dim, n_layers, batch_first=True, bidirectional = self.bidirectional) \n",
        "        # if rnn model is bidirectional then output troech tensor stacked forward and backward vectors\n",
        "        if( self.bidirectional ): \n",
        "          # use decoder dense layer to reduce the channel size to hidden_dim since decoder working in reccursive way \n",
        "          self.decoder_dense = nn.Linear( hidden_dim*2 , hidden_dim ) \n",
        "\n",
        "        else:\n",
        "          self.decoder_dense = nn.Linear( hidden_dim , hidden_dim ) \n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim , output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "        # Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        outputs = torch.zeros( batch_size , self.decoder_length , self.hidden_dim )\n",
        "        # encode input vector  (input_size --> hidden_dim)\n",
        "        x = self.encoder_input( x )\n",
        "\n",
        "        # decoder working as reccursive way , output need to have 11 predictions in reccursive way\n",
        "        for t in range( self.decoder_length ): \n",
        "            # forward pass the rnn layer and output one time step prediction and hidden tensor\n",
        "            decoder_output, hidden = self.rnn( x , hidden )\n",
        "            # map the cocatenated bidrectional vector into hidden_dim\n",
        "            decoder_output = self.decoder_dense( decoder_output.squeeze(1) )\n",
        "           \n",
        "            # stck the outputs\n",
        "            outputs[:,t,:] = decoder_output\n",
        "            x = decoder_output.unsqueeze(1)\n",
        "\n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out = self.fc(outputs)\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        if(self.bidirectional ):\n",
        "          hidden = torch.zeros(self.n_layers*2, batch_size, self.hidden_dim, device = DEVICE)\n",
        "          return hidden\n",
        "        else:\n",
        "          hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim, device = DEVICE)\n",
        "        return hidden"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8slkptM6BLgo"
      },
      "source": [
        "def plot_train_val(x, train, val, train_label,\n",
        "                   val_label, title, y_label,\n",
        "                   color):\n",
        "  fig = plt.figure( figsize=(6,6) )\n",
        "  plt.plot(x, train, label=train_label, color=color)\n",
        "  plt.plot(x, val, label=val_label, color=color, linestyle='--')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel(y_label)\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "  parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return parameters\n",
        "\n",
        "\n",
        "def init_weights(m):\n",
        "  if type(m) in (nn.Linear, nn.Conv1d):\n",
        "    nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "\n",
        "\n",
        "# Training functioN\n",
        "def train(model, device, train_loader, valid_loader, epochs, learning_rate):\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  \n",
        "  train_loss, validation_loss = [], []\n",
        "  train_acc, validation_acc = [], []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    #train\n",
        "    model.train()\n",
        "    running_loss = 0.\n",
        "    correct, total = 0, 0\n",
        "    steps = 0\n",
        "    for idx, batch in enumerate(train_loader):\n",
        "      text = batch[\"Sample\"].to(device)\n",
        "      target = batch['Class'].to(device)\n",
        "      target = target.type(torch.LongTensor)\n",
        "      text, target = text.to(device), target.to(device)\n",
        "      # add micro for coding training loop\n",
        "      optimizer.zero_grad()\n",
        "      output, hidden = model(text.unsqueeze(1))\n",
        "\n",
        "      #pdb.set_trace()\n",
        "      #print(output.shape, target.shape, target.view(-1).shape)\n",
        "\n",
        "      # reshape the output and target as 2d vector which accepted by the cross_entropy loss\n",
        "      loss = criterion( output.contiguous().view(-1,target.shape[-1]) , torch.max( target , 2)[1].view(-1) )\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      steps += 1\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # get accuracy\n",
        "      _, predicted = torch.max(output, 2)\n",
        "      #print(predicted)\n",
        "      #predicted = torch.round(output.squeeze())\n",
        "      total += target.size(0)*target.size(1)\n",
        "      correct += (predicted == torch.max(target,2)[1]  ).sum().item()\n",
        "\n",
        "    train_loss.append(running_loss/len(train_loader))\n",
        "    train_acc.append(correct/total)\n",
        "\n",
        "    if( epoch % 10 == 0 ):\n",
        "\n",
        "      print(f'Epoch: {epoch + 1}, '\n",
        "            f'Training Loss: {running_loss/len(train_loader):.4f}, '\n",
        "            f'Training Accuracy: {100*correct/total: .2f}%')\n",
        "\n",
        "    # evaluate on validation data\n",
        "    model.eval()\n",
        "    running_loss = 0.\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for idx, batch in enumerate(valid_loader):\n",
        "        text = batch[\"Sample\"].to(device)\n",
        "        #print(type(text), text.shape)\n",
        "        target = batch['Class'].to(device)\n",
        "        target = torch.autograd.Variable(target).long()\n",
        "        text, target = text.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output , _ = model(text.unsqueeze(1))\n",
        "        \n",
        "        loss = criterion(output.contiguous().view(-1,target.shape[-1]) , torch.max( target , 2)[1].view(-1) )\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # get accuracy\n",
        "        _, predicted = torch.max(output, 2)\n",
        "        #predicted = torch.round(output.squeeze())\n",
        "        total += target.size(0)*target.size(1)\n",
        "        correct += (predicted == torch.max(target,2)[1] ).sum().item()\n",
        "\n",
        "    validation_loss.append(running_loss/len(valid_loader))\n",
        "    validation_acc.append(correct/total)\n",
        "\n",
        "    if( epoch % 10 == 0 ):\n",
        "\n",
        "      print (f'Validation Loss: {running_loss/len(valid_loader):.4f}, '\n",
        "            f'Validation Accuracy: {100*correct/total: .2f}%\\n')\n",
        "\n",
        "  return train_loss, train_acc, validation_loss, validation_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7mElthTHKdV"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXB6LiaVzTaD"
      },
      "source": [
        "# Model hyperparamters\n",
        "#vocab_size = len(word_array)\n",
        "learning_rate = 1e-4\n",
        "hidden_dim = 200\n",
        "output_size = 40\n",
        "input_size = 300\n",
        "epochs = 200\n",
        "n_layers = 2\n",
        "\n",
        "# Initialize model, training and testing\n",
        "set_seed(SEED)\n",
        "vanilla_rnn_model = VanillaRNN(input_size, output_size, hidden_dim, n_layers)\n",
        "#vanilla_rnn_model = VanillaRNN(output_size, input_size, RNN_size, fc_size, DEVICE)\n",
        "vanilla_rnn_model.to(DEVICE)\n",
        "vanilla_rnn_start_time = time.time()\n",
        "vanilla_train_loss, vanilla_train_acc, vanilla_validation_loss, vanilla_validation_acc = train(vanilla_rnn_model,\n",
        "                                                                                               DEVICE,\n",
        "                                                                                               train_loader,\n",
        "                                                                                               valid_loader,\n",
        "                                                                                               epochs = epochs,\n",
        "                                                                                               learning_rate = learning_rate)\n",
        "print(\"--- Time taken to train = %s seconds ---\" % (time.time() - vanilla_rnn_start_time))\n",
        "\n",
        "\n",
        "# Number of model parameters\n",
        "print(f'Number of parameters = {count_parameters(vanilla_rnn_model)}')\n",
        "\n",
        "\n",
        "# Plot accuracy curves\n",
        "\n",
        "plot_train_val(np.arange(0, epochs), vanilla_train_acc, vanilla_validation_acc,\n",
        "               'train accuracy', 'val accuracy',\n",
        "               'Word Production Accuracy', 'accuracy',\n",
        "               color='C0')\n",
        "\n",
        "\n",
        "plot_train_val(np.arange(0, epochs), vanilla_train_loss,\n",
        "               vanilla_validation_loss,\n",
        "               'train loss', 'val loss',\n",
        "               'Word Production Accuracy',\n",
        "               'loss [a.u.]',\n",
        "               color='C0')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NamFjB82HM-K"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul6v0tn6HOv3"
      },
      "source": [
        "# save the trained model WordProd for future usage\n",
        "torch.save({\n",
        "            'model_state_dict': vanilla_rnn_model.state_dict(),\n",
        "            },  \"WordProd.pth\" )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWeVVoS_Iq9p"
      },
      "source": [
        "## Load the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c-AnplCItBA",
        "outputId": "257f4401-e452-4fb8-fa17-b706592e34dd"
      },
      "source": [
        "# Model hyperparamters\n",
        "#vocab_size = len(word_array)\n",
        "hidden_dim = 200\n",
        "output_size = 40\n",
        "input_size = 300\n",
        "n_layers = 2\n",
        "\n",
        "trained_rnn_model = VanillaRNN(input_size, output_size, hidden_dim, n_layers)\n",
        "# load the trained weights into the model\n",
        "trained_rnn_model.load_state_dict( torch.load(\"WordProd.pth\")[\"model_state_dict\"] )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Llb5vEF42Kf"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaYIJu7Sp6dD"
      },
      "source": [
        "# Training functioN\n",
        "def test_rnnmodel(model, device, test_loader):\n",
        "\n",
        "  # evaluate on validation data\n",
        "  model.eval()\n",
        "  running_loss = 0.\n",
        "  correct, total = 0, 0\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  with torch.no_grad():\n",
        "    for idx, batch in enumerate( test_loader):\n",
        "        text = batch[\"Sample\"].to(device)\n",
        "        #print(type(text), text.shape)\n",
        "        target = batch['Class'].to(device)\n",
        "        target = torch.autograd.Variable(target).long()\n",
        "        text, target = text.to(device), target.to(device)\n",
        "\n",
        "        output , _ = model(text.unsqueeze(1))\n",
        "        \n",
        "        loss = criterion(output.contiguous().view(-1,target.shape[-1]) , torch.max( target , 2)[1].view(-1) )\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # get accuracy\n",
        "        _, predicted = torch.max(output, 2)\n",
        "        #predicted = torch.round(output.squeeze())\n",
        "        total += target.size(0)*target.size(1)\n",
        "        correct += (predicted == torch.max(target,2)[1] ).sum().item()\n",
        "\n",
        "\n",
        "  print (f'Test Dataset Loss: {running_loss/len(test_loader):.4f}, '\n",
        "           f'Test Dataset Accuracy: {100*correct/total: .2f}%\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLZuUtfS6DNs"
      },
      "source": [
        "## Convert Test Data and measure test accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2FZ31-56HoX"
      },
      "source": [
        "def measure_test_stats( model , test_set ):\n",
        "  test_raw_words , X_test , y_test = data_preprocessing( test_set ) \n",
        "\n",
        "  # convert the indexed numpy array into torch tensor with int64 dtype\n",
        "  y_test_tensor = torch.tensor( y_test , dtype=torch.int64 )\n",
        "  # troech tensor one hot encoding\n",
        "  y_test_one_hot_encoding = F.one_hot(y_test_tensor, num_classes=40)\n",
        "\n",
        "  # convert the X_in , y into torch tenors\n",
        "  X_test = torch.from_numpy(X_test)\n",
        "  y_test = y_test_one_hot_encoding\n",
        "  test_raw_words = np.array( test_raw_words )\n",
        "\n",
        "  # define the test dataset and test loader\n",
        "  test_dset = CustomDataset( test_raw_words ,  X_test , y_test )\n",
        "  test_loader = DataLoader( test_dset, batch_size=32 , shuffle=False)\n",
        "\n",
        "  # evaluate the model using the test set\n",
        "  test_rnnmodel( model , DEVICE , test_loader )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flH0uUSZ77ZW",
        "outputId": "f8c30d08-3040-4307-867f-24a62857993c"
      },
      "source": [
        "# evaluate the model on test dataset\n",
        "measure_test_stats( trained_rnn_model , test_words )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Dataset Loss: 0.0785, Test Dataset Accuracy:  98.51%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD7OQg-S5hhk"
      },
      "source": [
        "## Convert Model Predictions to Word Matrix Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdUCCoDcCD1O"
      },
      "source": [
        "def out_to_arp( model , data_loader , device ):\n",
        "  # dict for convert index to phon character\n",
        "  replace_idx2phons={  i_val:i_key  for i_key , i_val in replace_phons.items() }\n",
        "  final_df =[]\n",
        "  # headers\n",
        "  header = ['Word', '1', '2', '3', '4', '5', '6','7', '8', '9', '10', '11']\n",
        "  # evaluate on validation data\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, batch in enumerate( data_loader):\n",
        "\n",
        "        text = batch[\"Sample\"].to(device)\n",
        "        word = batch[\"Sample_word\"]\n",
        "\n",
        "        text = text.to(device)\n",
        "\n",
        "        output , _ = model(text.unsqueeze(1))\n",
        "\n",
        "        # get accuracy\n",
        "        _, predicted = torch.max(output, 2)\n",
        "\n",
        "        # convert backto word matrix format\n",
        "      \n",
        "        for i_word , i_pred in zip(  word , predicted ):\n",
        "          i_output = {}\n",
        "          i_output['Word'] = i_word\n",
        "          for i_head , i_pred_word in zip( header[1:] , i_pred ):\n",
        "            i_output[i_head] = replace_idx2phons[i_pred_word.item()]\n",
        "\n",
        "          final_df.append( i_output )\n",
        "\n",
        "  # convert the results to word matrix\n",
        "  df_out = pd.DataFrame( final_df )\n",
        "\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AvRzCp1V6Dj"
      },
      "source": [
        "## Predictions from train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Wvc-8YloDA-F",
        "outputId": "f7655c35-58cd-4d50-db84-f4d1051eedad"
      },
      "source": [
        "out_to_arp( trained_rnn_model , valid_loader , DEVICE )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>penny</td>\n",
              "      <td>P</td>\n",
              "      <td>EH</td>\n",
              "      <td>N</td>\n",
              "      <td>IY</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>garland</td>\n",
              "      <td>HH</td>\n",
              "      <td>AA</td>\n",
              "      <td>R</td>\n",
              "      <td>L</td>\n",
              "      <td>AH</td>\n",
              "      <td>N</td>\n",
              "      <td>D</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pole</td>\n",
              "      <td>P</td>\n",
              "      <td>OW</td>\n",
              "      <td>L</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>burrito</td>\n",
              "      <td>B</td>\n",
              "      <td>ER</td>\n",
              "      <td>IY</td>\n",
              "      <td>T</td>\n",
              "      <td>OW</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>brake</td>\n",
              "      <td>B</td>\n",
              "      <td>R</td>\n",
              "      <td>EY</td>\n",
              "      <td>K</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>nut</td>\n",
              "      <td>N</td>\n",
              "      <td>AH</td>\n",
              "      <td>T</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>chipmunk</td>\n",
              "      <td>CH</td>\n",
              "      <td>IH</td>\n",
              "      <td>P</td>\n",
              "      <td>M</td>\n",
              "      <td>AH</td>\n",
              "      <td>NG</td>\n",
              "      <td>K</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1351</th>\n",
              "      <td>zucchini</td>\n",
              "      <td>Z</td>\n",
              "      <td>UW</td>\n",
              "      <td>K</td>\n",
              "      <td>IY</td>\n",
              "      <td>N</td>\n",
              "      <td>IY</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1352</th>\n",
              "      <td>manatee</td>\n",
              "      <td>M</td>\n",
              "      <td>AE</td>\n",
              "      <td>N</td>\n",
              "      <td>AH</td>\n",
              "      <td>T</td>\n",
              "      <td>IY</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1353</th>\n",
              "      <td>goalpost</td>\n",
              "      <td>M</td>\n",
              "      <td>OW</td>\n",
              "      <td>L</td>\n",
              "      <td>P</td>\n",
              "      <td>OW</td>\n",
              "      <td>S</td>\n",
              "      <td>T</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1354 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word   1   2   3   4   5   6  7 8  9  10 11\n",
              "0        penny   P  EH   N  IY                       \n",
              "1      garland  HH  AA   R   L  AH   N  D            \n",
              "2         pole   P  OW   L                           \n",
              "3      burrito   B  ER  IY   T  OW                   \n",
              "4        brake   B   R  EY   K                       \n",
              "...        ...  ..  ..  ..  ..  ..  .. .. .. .. .. ..\n",
              "1349       nut   N  AH   T                           \n",
              "1350  chipmunk  CH  IH   P   M  AH  NG  K            \n",
              "1351  zucchini   Z  UW   K  IY   N  IY               \n",
              "1352   manatee   M  AE   N  AH   T  IY               \n",
              "1353  goalpost   M  OW   L   P  OW   S  T            \n",
              "\n",
              "[1354 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN7bPVtrEBJg"
      },
      "source": [
        "## Get the predictions for the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "h7U2Y5zqESVD",
        "outputId": "8f9829a2-cb6b-438e-aca1-a1803c889a57"
      },
      "source": [
        "#ChNGED TO MATCH NEW INPUT WORDS\n",
        "#url = 'https://raw.githubusercontent.com/AlexSwiderski/SwiderskiLakhani/main/Just_Item_Names.csv'\n",
        "url = test\n",
        "words_test = pd.read_csv(url , header=None)\n",
        "words_test.fillna('', inplace = True)\n",
        "\n",
        "words_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anchor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>baby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>whistle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>wig</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>window</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>zebra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>zipper</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0\n",
              "0    ambulance\n",
              "1       anchor\n",
              "2        apple\n",
              "3         baby\n",
              "4         ball\n",
              "..         ...\n",
              "170    whistle\n",
              "171        wig\n",
              "172     window\n",
              "173      zebra\n",
              "174     zipper\n",
              "\n",
              "[175 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BQgemjF_11h"
      },
      "source": [
        "#word_array = np.empty((0, 300))\n",
        "\n",
        "def get_preds_test( model , input_dataframe ):\n",
        "\n",
        "\n",
        "  X2 , test_raw_words = [] , []\n",
        "\n",
        "  for idx, row in enumerate(words_test.iterrows()):\n",
        "      try:\n",
        "          #get the glove vector for each word\n",
        "          word_array = np.empty((0, 300))\n",
        "          result = glove_model300.word_vec(row[1][0])\n",
        "          word_array = np.append(word_array, [result], axis = 0)\n",
        "          X2.append(result)\n",
        "          test_raw_words.append( row[1][0] )\n",
        "\n",
        "      except:\n",
        "          #X[idx] = 'None'\n",
        "          pass\n",
        "  # convert x_test into numpy array\n",
        "  x_test = np.array(X2)\n",
        "\n",
        "  # convert the X_in , y into torch tenors\n",
        "  X_test = torch.from_numpy( x_test )\n",
        "  test_raw_words = np.array( test_raw_words )\n",
        "  # define the test dataset\n",
        "  dataset= [ { \"Sample_word\": test_raw_words , \"Sample\":X_test }  ]\n",
        "  # get the model output for the test dataset\n",
        "  df_pred = out_to_arp( model , dataset , DEVICE )\n",
        "\n",
        "  return df_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4ufuCOvV-co"
      },
      "source": [
        "## output predictions for test csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "R4AttrcaGbGN",
        "outputId": "60e131cd-5b72-47fd-f773-bc408b301ee1"
      },
      "source": [
        "PNT_output = get_preds_test( trained_rnn_model , test_words )\n",
        "# preditions for test csv file\n",
        "PNT_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ambulance</td>\n",
              "      <td>AO</td>\n",
              "      <td>R</td>\n",
              "      <td>T</td>\n",
              "      <td>IH</td>\n",
              "      <td>SH</td>\n",
              "      <td>K</td>\n",
              "      <td>AH</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anchor</td>\n",
              "      <td>AE</td>\n",
              "      <td>NG</td>\n",
              "      <td>K</td>\n",
              "      <td>ER</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apple</td>\n",
              "      <td>AE</td>\n",
              "      <td>P</td>\n",
              "      <td>AH</td>\n",
              "      <td>L</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>baby</td>\n",
              "      <td>B</td>\n",
              "      <td>EY</td>\n",
              "      <td>B</td>\n",
              "      <td>IY</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ball</td>\n",
              "      <td>S</td>\n",
              "      <td>AO</td>\n",
              "      <td>L</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>whistle</td>\n",
              "      <td>W</td>\n",
              "      <td>IH</td>\n",
              "      <td>S</td>\n",
              "      <td>AH</td>\n",
              "      <td>L</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>wig</td>\n",
              "      <td>W</td>\n",
              "      <td>IH</td>\n",
              "      <td>G</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>window</td>\n",
              "      <td>W</td>\n",
              "      <td>IH</td>\n",
              "      <td>N</td>\n",
              "      <td>D</td>\n",
              "      <td>OW</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>zebra</td>\n",
              "      <td>G</td>\n",
              "      <td>IY</td>\n",
              "      <td>B</td>\n",
              "      <td>R</td>\n",
              "      <td>AH</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>zipper</td>\n",
              "      <td>Z</td>\n",
              "      <td>IH</td>\n",
              "      <td>P</td>\n",
              "      <td>ER</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word   1   2   3   4   5  6   7  8 9  10 11\n",
              "0    ambulance  AO   R   T  IH  SH  K  AH  N         \n",
              "1       anchor  AE  NG   K  ER                       \n",
              "2        apple  AE   P  AH   L                       \n",
              "3         baby   B  EY   B  IY                       \n",
              "4         ball   S  AO   L                           \n",
              "..         ...  ..  ..  ..  ..  .. ..  .. .. .. .. ..\n",
              "170    whistle   W  IH   S  AH   L                   \n",
              "171        wig   W  IH   G                           \n",
              "172     window   W  IH   N   D  OW                   \n",
              "173      zebra   G  IY   B   R  AH                   \n",
              "174     zipper   Z  IH   P  ER                       \n",
              "\n",
              "[175 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzKFpHrtJSmQ"
      },
      "source": [
        "## Injest noise into the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8K8IyxiGhu0",
        "outputId": "127d1d03-752f-4747-84e4-f34e32f9ad63"
      },
      "source": [
        "import copy\n",
        "\n",
        "# define the bool value for noise model layers\n",
        "noise_encoder_input = True\n",
        "noise_rnn = True\n",
        "noise_decoder_dense = True\n",
        "noise_fc= True\n",
        "\n",
        "def add_noise_to_weights( model ):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if noise_encoder_input :\n",
        "            print(\"Adding noise to encoder input layer\")\n",
        "            # add random gaussian noise into linear layer weights\n",
        "            weight_shape = model.encoder_input.weight.size()\n",
        "            bias_shape = model.encoder_input.bias.size()\n",
        "\n",
        "            model.encoder_input.weight.add_( torch.randn( weight_shape ) * 0.01)\n",
        "            model.encoder_input.bias.add_( torch.randn( bias_shape ) * 0.01)\n",
        "\n",
        "        if noise_decoder_dense :\n",
        "            print(\"Adding noise to decoder dense layer\")\n",
        "            # add random gaussian noise into linear layer weights\n",
        "            weight_shape = model.decoder_dense.weight.size()\n",
        "            bias_shape = model.decoder_dense.bias.size()\n",
        "\n",
        "            model.decoder_dense.weight.add_( torch.randn( weight_shape ) * 0.01)\n",
        "            model.decoder_dense.bias.add_( torch.randn( bias_shape ) * 0.01)\n",
        "\n",
        "        if noise_fc :\n",
        "            print(\"Adding noise to final classification layer\")\n",
        "            # add random gaussian noise into linear layer weights\n",
        "            weight_shape = model.fc.weight.size()\n",
        "            bias_shape = model.fc.bias.size()\n",
        "            \n",
        "            model.fc.weight.add_( torch.randn( weight_shape ) * 0.01)\n",
        "            model.fc.bias.add_( torch.randn( bias_shape ) * 0.01)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      if(noise_rnn):\n",
        "        print(\"Adding noise to RNN layer\")\n",
        "        # add noise to the rnn module seperately\n",
        "        for i_params in model.rnn.all_weights :\n",
        "          for i_hidden_weight in i_params :\n",
        "            # add gaussian random noise to each rnn hidden state\n",
        "            i_hidden_weight.add_(  torch.randn( i_hidden_weight.shape ) * 0.05 )\n",
        "\n",
        "    return model\n",
        "\n",
        "        \n",
        "noise_rnn_model = copy.deepcopy(trained_rnn_model)\n",
        "# define the noise injected model\n",
        "noise_rnn_model = add_noise_to_weights( trained_rnn_model )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding noise into encoder input layer\n",
            "Adding noise to decoder dense layer\n",
            "Adding noise to final classification layer\n",
            "Adding noise to RNN layer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHgEoUViVBjZ"
      },
      "source": [
        "## Evaluate the model after adding noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWilwR1oMi18",
        "outputId": "9ccf7044-0ff9-4b3e-960a-b53e0f9b62e9"
      },
      "source": [
        "# evaluate the noise model on test dataset\n",
        "measure_test_stats( noise_rnn_model , test_words )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Dataset Loss: 2.1286, Test Dataset Accuracy:  67.47%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-2sCGYVFQg"
      },
      "source": [
        "## Predictions from the noise model on test csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "MP9TDZWHPbwo",
        "outputId": "c20cf8af-b81d-4326-94d7-f649f99b0096"
      },
      "source": [
        "Noisy_output = get_preds_test( noise_rnn_model , test_words )\n",
        "# preditions for test csv file\n",
        "Noisy_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ambulance</td>\n",
              "      <td>UW</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>IH</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>D</td>\n",
              "      <td>ER</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anchor</td>\n",
              "      <td>AE</td>\n",
              "      <td>G</td>\n",
              "      <td>R</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apple</td>\n",
              "      <td>K</td>\n",
              "      <td>P</td>\n",
              "      <td>IY</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>baby</td>\n",
              "      <td>D</td>\n",
              "      <td>AA</td>\n",
              "      <td>K</td>\n",
              "      <td>IY</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ball</td>\n",
              "      <td>S</td>\n",
              "      <td>AE</td>\n",
              "      <td>K</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>whistle</td>\n",
              "      <td>T</td>\n",
              "      <td>IH</td>\n",
              "      <td>R</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>wig</td>\n",
              "      <td>S</td>\n",
              "      <td>AA</td>\n",
              "      <td>R</td>\n",
              "      <td>L</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>window</td>\n",
              "      <td>K</td>\n",
              "      <td>AE</td>\n",
              "      <td>T</td>\n",
              "      <td>ER</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>zebra</td>\n",
              "      <td>D</td>\n",
              "      <td>AA</td>\n",
              "      <td>AE</td>\n",
              "      <td>TH</td>\n",
              "      <td>AH</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>zipper</td>\n",
              "      <td>P</td>\n",
              "      <td>IH</td>\n",
              "      <td>P</td>\n",
              "      <td>ER</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word   1   2   3   4   5  6  7   8 9  10 11\n",
              "0    ambulance  UW   G   T  IH   N  N  D  ER         \n",
              "1       anchor  AE   G   R                           \n",
              "2        apple   K   P  IY                           \n",
              "3         baby   D  AA   K  IY                       \n",
              "4         ball   S  AE   K                           \n",
              "..         ...  ..  ..  ..  ..  .. .. ..  .. .. .. ..\n",
              "170    whistle   T  IH   R                           \n",
              "171        wig   S  AA   R   L                       \n",
              "172     window   K  AE   T  ER                       \n",
              "173      zebra   D  AA  AE  TH  AH                   \n",
              "174     zipper   P  IH   P  ER   N  T                \n",
              "\n",
              "[175 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}